{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Importing ...\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from   torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms # Using TorchIO may help in 3D augmentation *\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define your model architecture here\n",
    "# print(\"Defining Classes ...\")\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels , out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool3d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module): #\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffZ = x2.size()[2] - x1.size()[2] # NCXYZ\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = nn.functional.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
    "                                    diffY // 2, diffY - diffY // 2,\n",
    "                                    diffZ // 2, diffZ - diffZ // 2))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet3D(nn.Module): ### Add dropout!\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.inc = DoubleConv(in_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256)\n",
    "        self.up2 = Up(512, 128)\n",
    "        self.up3 = Up(256, 64)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        output = self.outc(x)\n",
    "        return output\n",
    "\n",
    "# Define a custom transform class for applying the same random crop\n",
    "class RandomCrop3D: ###\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "\n",
    "        # Get the input size\n",
    "        input_size = inputs.shape[2:] ###\n",
    "\n",
    "        # Calculate the starting index for the crop\n",
    "        start_indexes = [random.randint(0, input_size[i] - self.output_size[i]) for i in range(3)]\n",
    "\n",
    "        # Perform the crop on both inputs and targets\n",
    "        inputs  = inputs [:,:, start_indexes[0]:start_indexes[0] + self.output_size[0], \n",
    "                               start_indexes[1]:start_indexes[1] + self.output_size[1],\n",
    "                               start_indexes[2]:start_indexes[2] + self.output_size[2]]\n",
    "\n",
    "        targets = targets[:,:, start_indexes[0]:start_indexes[0] + self.output_size[0], \n",
    "                               start_indexes[1]:start_indexes[1] + self.output_size[1],\n",
    "                               start_indexes[2]:start_indexes[2] + self.output_size[2]]\n",
    "\n",
    "        return inputs, targets\n",
    "\n",
    "# Define the output size for random cropping\n",
    "output_size = (128, 128, 128)\n",
    "\n",
    "# Define the transforms\n",
    "transform = transforms.Compose([\n",
    "    RandomCrop3D(output_size),              # Custom random crop\n",
    "    # transforms.RandomVerticalFlip(),        # Random vertical flipping\n",
    "    # transforms.RandomHorizontalFlip()        # Random horizontal flipping\n",
    "])\n",
    "\n",
    "\n",
    "# Define your dataset class for loading CT images and masks\n",
    "\n",
    "class CTImageDataset(torch.utils.data.Dataset): ###\n",
    "    def __init__(self, image_paths, mask_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths  = mask_paths\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = nib.load(self.image_paths[index]).get_fdata()\n",
    "        mask  = nib.load(self.mask_paths [index]).get_fdata()\n",
    "        image = torch.from_numpy(image).unsqueeze(0).float() ### 1-Channel?!\n",
    "        mask  = torch.from_numpy(mask ).unsqueeze(0).long() ### Changed!\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training function\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device): ###\n",
    "    model.train() ###\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        # print(f\"Batch {batch_idx+1} Started\")\n",
    "\n",
    "        images = images.to(device)\n",
    "        masks  = masks .to(device)\n",
    "\n",
    "        # Apply transforms to the inputs and targets\n",
    "        images, masks = transform((images, masks))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        # print(\"Passing through Model ...\")\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        # print(\"CrossEnthropy() ...\")\n",
    "        loss = criterion(outputs, torch.squeeze(masks, dim=1)) ###\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        # print(\"Backward ...\")\n",
    "        loss.backward()\n",
    "        # print(\"Step ...\")\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your training parameters\n",
    "# print(\"Setting Parameters & Instanciating ...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") ####1\n",
    "epochs = 10\n",
    "batch_size = 1 #4 ###\n",
    "learning_rate = 0.0001 #0.001 ###\n",
    "\n",
    "# Create your model instance\n",
    "\n",
    "model = UNet3D(in_channels=1, out_channels=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Create your dataset and data loader instances\n",
    "\n",
    "image_paths_train = [\"Data\\SPIROMCS-Case36-Vx3.nii.gz\"        , \"Data\\SPIROMCS-Case43-Vx3.nii.gz\"]\n",
    "mask_paths_train  = [\"Data\\SPIROMCS-Case36-012Labelmap.nii.gz\", \"Data\\SPIROMCS-Case43-012Labelmap.nii.gz\"]\n",
    "train_dataset = CTImageDataset(image_paths_train, mask_paths_train) ### Cases 43&36 ### M:1 A:2 V:3 > 012!\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) ### Mask: B=1?C=1?XYZ? #shuffle=True\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() ####2 ignore_index (int, optional) ***\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of trainable parameters\n",
    "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training loop\n",
    "print(\"Start Training ...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device) ########\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\") ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image = nib.load(\"Data\\SPIROMCS-Case36-Vx3.nii.gz\").get_fdata()\n",
    "mask  = nib.load(\"Data\\SPIROMCS-Case36-012Labelmap.nii.gz\").get_fdata()\n",
    "\n",
    "image = torch.from_numpy(image).unsqueeze(0).float() ### Channels=1 !\n",
    "mask  = torch.from_numpy(mask ).unsqueeze(0).long()  ### Changed!\n",
    "\n",
    "input_tensor = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "mask_tensor  = mask .unsqueeze(0).to(device)  # Add batch dimension ############## to(device) after tramsform!\n",
    "\n",
    "input_tensor, mask_tensor = transform((input_tensor, mask_tensor))\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output_tensor = model(input_tensor)\n",
    "\n",
    "# Post-process the output tensor\n",
    "output_tensor = torch.argmax(output_tensor, dim=1)  # Convert to class labels (assuming CrossEntropyLoss was used)\n",
    "\n",
    "# Convert the output tensor to numpy array\n",
    "output_array = output_tensor.squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itkwidgets\n",
    "# # import itk\n",
    "# # itk_np = itk.GetImageFromArray(output_array)\n",
    "# # itk.imwrite(output_array, output_file_name)\n",
    "# # view(output_array)\n",
    "# # # view ?\n",
    "# your_array = np.random.random((64, 64, 64))\n",
    "# # Visualize the 3D numpy array\n",
    "# itkwidgets.view(your_array)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import itk\n",
    "\n",
    "# # Generate or load your 3D numpy array\n",
    "# your_array = np.random.random((64, 64, 64))  # Replace with your own 3D numpy array\n",
    "\n",
    "# # Convert numpy array to ITK image\n",
    "# image = itk.GetImageFromArray(your_array)\n",
    "\n",
    "# # Visualize the ITK image\n",
    "# itkwidgets.view(image)\n",
    "\n",
    "\n",
    "# import itkwidgets\n",
    "# import numpy as np\n",
    "# import itk\n",
    "\n",
    "# # Generate or load your 3D numpy array\n",
    "# # your_array = np.random.random((64, 64, 64))  # Replace with your own 3D numpy array\n",
    "\n",
    "# # Ensure the array has the correct shape and datatype\n",
    "# your_array = np.asarray(output_array, dtype=np.float32)\n",
    "\n",
    "# # Create an ITK image from the numpy array\n",
    "# # image = itk.image_view_from_array(your_array)\n",
    "# image = itk.GetImageFromArray(your_array)\n",
    "\n",
    "# # Visualize the ITK image\n",
    "# itkwidgets.view(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipyvolume as ipv\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate or load your 3D numpy array\n",
    "# your_array = np.random.random((64, 64, 64))  # Replace with your own 3D numpy array\n",
    "\n",
    "# # Visualize the 3D numpy array\n",
    "# ipv.quickvolshow(your_array)\n",
    "\n",
    "# # Display the visualization\n",
    "# # ipv.show()\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import ipyvolume as ipv\n",
    "# V = np.zeros((128,128,128)) # our 3d array\n",
    "# # outer box\n",
    "# V[30:-30,30:-30,30:-30] = 0.75\n",
    "# V[35:-35,35:-35,35:-35] = 0.0\n",
    "# # inner box\n",
    "# V[50:-50,50:-50,50:-50] = 0.25\n",
    "# V[55:-55,55:-55,55:-55] = 0.0\n",
    "# ipv.quickvolshow(V, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageSliceViewer3D & ipywidgets\n",
    "import ipywidgets as ipyw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ImageSliceViewer3D:\n",
    "    \"\"\" \n",
    "    ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
    "    ipython notebooks. \n",
    "    \n",
    "    User can interactively change the slice plane selection for the image and \n",
    "    the slice plane being viewed. \n",
    "\n",
    "    Argumentss:\n",
    "    Volume = 3D input image\n",
    "    figsize = default(8,8), to set the size of the figure\n",
    "    cmap = default('plasma'), string for the matplotlib colormap. You can find \n",
    "    more matplotlib colormaps on the following link:\n",
    "    https://matplotlib.org/users/colormaps.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, volume, figsize=(8,8), cmap='plasma'):\n",
    "        self.volume = volume\n",
    "        self.figsize = figsize\n",
    "        self.cmap = cmap\n",
    "        self.v = [np.min(volume), np.max(volume)]\n",
    "        \n",
    "        # Call to select slice plane\n",
    "        ipyw.interact(self.view_selection, view=ipyw.RadioButtons(\n",
    "            options=['x-y','y-z', 'z-x'], value='x-y', \n",
    "            description='Slice plane selection:', disabled=False,\n",
    "            style={'description_width': 'initial'}))\n",
    "    \n",
    "    def view_selection(self, view):\n",
    "        # Transpose the volume to orient according to the slice plane selection\n",
    "        orient = {\"y-z\":[1,2,0], \"z-x\":[2,0,1], \"x-y\": [0,1,2]}\n",
    "        self.vol = np.transpose(self.volume, orient[view])\n",
    "        maxZ = self.vol.shape[2] - 1\n",
    "        \n",
    "        # Call to view a slice within the selected slice plane\n",
    "        ipyw.interact(self.plot_slice, \n",
    "            z=ipyw.IntSlider(min=0, max=maxZ, step=1, continuous_update=False, \n",
    "            description='Image Slice:'))\n",
    "        \n",
    "    def plot_slice(self, z):\n",
    "        # Plot slice for the given plane and slice\n",
    "        self.fig = plt.figure(figsize=self.figsize)\n",
    "        plt.imshow(self.vol[:,:,z], cmap=plt.get_cmap(self.cmap), \n",
    "            vmin=self.v[0], vmax=self.v[1])\n",
    "        \n",
    "# Create a 3D array with random numbers\n",
    "x = np.random.rand(256,256,96)\n",
    "\n",
    "ImageSliceViewer3D(x)\n",
    "\n",
    "# The static rendering of Github does not display the image widget, and the \n",
    "# ability to interact with the image widget did not work with nbviewer when \n",
    "# last (26/05/2018) checked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas/Notes:\n",
    "# Normalization ****\n",
    "# Dropout\n",
    "# Several threads and gpus\n",
    "\n",
    "# nn.CrossEntropyLoss(): label_smoothing=0.0?!!\n",
    "\n",
    "# np.prod(input_tensor.size())/8*32 =\n",
    "# print(input_tensor.storage().nbytes())\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install scipy\n",
    "\n",
    "# python -c \"import torch; print(torch.cuda.is_available())\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
